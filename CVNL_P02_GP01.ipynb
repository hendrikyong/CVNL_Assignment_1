{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvIVIGJpvrtAn7HhZbuSK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendrikyong/CVNL_Assignment_1/blob/main/CVNL_P02_GP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset from kaggle\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "#download latest version\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "#list files in the dataset folder\n",
        "print(\"Path to dataset files:\", path)\n",
        "files = os.listdir(path)\n",
        "print(\"Files in the dataset:\", files)\n",
        "\n",
        "#define paths to the training and testing data directories\n",
        "train_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_test/asl_alphabet_test'\n",
        "\n",
        "#reorganise files\n",
        "#what is needed to be done is that from the test_dir for each image get first letter since all images are\n",
        "#labelled as letter_test.jpg and create a folder and add that image inside that folder\n",
        "import shutil\n",
        "\n",
        "for filename in os.listdir(test_dir):\n",
        "    if filename.endswith('.jpg'): #checks that it is a jpg\n",
        "        letter = filename.split('_')[0] #get the first part of the filename before '_'\n",
        "\n",
        "        #create a folder for the letter if it doesn't exist\n",
        "        letter_folder = os.path.join(test_dir, letter)\n",
        "        if not os.path.exists(letter_folder):\n",
        "            os.makedirs(letter_folder)\n",
        "        shutil.move(os.path.join(test_dir, filename), os.path.join(letter_folder, filename)) #moves the image into the corresponding folder\n",
        "\n",
        "print(\"Data re-organising complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EzNs7EU3HlX",
        "outputId": "c003e5bb-f0bc-4a88-a57c-1cf67273d8c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/grassknoted/asl-alphabet?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.03G/1.03G [00:15<00:00, 70.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1\n",
            "Files in the dataset: ['asl_alphabet_test', 'asl_alphabet_train']\n",
            "Data re-organising complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_bi8mnfd866Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to calculate mean and std\n",
        "def calc_mean_std():\n",
        "  pass"
      ],
      "metadata": {
        "id": "2322pxsup3gG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model cnn model\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "'''\n",
        "typical architecture of a CNN\n",
        "1. input\n",
        "2. conv\n",
        "3. relu\n",
        "4. pooling\n",
        "5. fully connected layers\n",
        "5. output pred\n",
        "\n",
        "considerations:\n",
        "how many conv layers do i need for feature extraction?\n",
        "how many hidden layers?\n",
        "how many channels?\n",
        "'''\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=29):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            #conv1\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            #conv2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            #conv3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),  #flatten the tensor for fully connected layers\n",
        "            nn.Linear(128 * 16 * 16, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  #dropout for regularization\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "16Ev39ZJ-LUu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model and train the CNN\n",
        "'''\n",
        "1. input data\n",
        "2. preprocessing\n",
        "  - standardize images(dont need to images from the dataset already comes 200x200)\n",
        "  - color transformation\n",
        "  - rotate image\n",
        "3. feature extraction\n",
        "4. ML model\n",
        "'''\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "#normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomCrop(128, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std) #need to change the mean and std but im not sure change to what though\n",
        "    #i think need to calc mean and std with like the train_loader len(dataset) thingy ?\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomCrop(128, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "t6hb_HKj9mmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8372f9-11de-4509-f700-a940ce7f2597"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if gpu available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(device)\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "lr = 0.001\n",
        "model = CNN(num_classes=29)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zMUlw-pdUHZo",
        "outputId": "3b768e9a-2b27-4a86-8cc8-e65c86fda3f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=32768, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=29, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, loss_func, optimizer, device, epochs):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            #update tqdm with current metrics\n",
        "            progress_bar.set_postfix({\n",
        "                \"Loss\": f\"{epoch_loss / (batch_idx + 1):.4f}\",\n",
        "                \"Acc\": f\"{100. * correct / total:.2f}%\"\n",
        "            })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100. * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "gATnn1g5BByu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, loss_func, device):\n",
        "    model.eval()  #set model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in progress_bar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            #update tqdm with current metrics\n",
        "            progress_bar.set_postfix({\n",
        "                \"Loss\": f\"{test_loss / (total):.4f}\",\n",
        "                \"Acc\": f\"{100. * correct / total:.2f}%\"\n",
        "            })\n",
        "\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Accuracy: {100. * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "SToQKQTD0bKG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, loss_func, optimizer, device, epochs)\n",
        "evaluate(model, test_loader, loss_func, device)"
      ],
      "metadata": {
        "id": "x4kzN3hY6P3z",
        "outputId": "fe82c9be-78b9-4607-c49a-88cdf9dd8b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 1360/1360 [03:54<00:00,  5.79it/s, Loss=2.1809, Acc=31.96%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 2.1809, Accuracy: 31.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 1360/1360 [03:55<00:00,  5.79it/s, Loss=1.0831, Acc=61.79%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 1.0831, Accuracy: 61.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 1360/1360 [03:57<00:00,  5.73it/s, Loss=0.8137, Acc=71.00%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.8137, Accuracy: 71.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 1360/1360 [03:56<00:00,  5.74it/s, Loss=0.6710, Acc=76.15%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.6710, Accuracy: 76.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 1360/1360 [03:53<00:00,  5.82it/s, Loss=0.5821, Acc=79.23%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.5821, Accuracy: 79.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, Loss=0.0635, Acc=75.00%]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.7778, Accuracy: 75.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}