{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzmtCeZUubacqg7k5+FbRG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendrikyong/CVNL_Assignment_1/blob/main/CVNL_P02_GP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting dataset\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "# List files in the dataset folder\n",
        "print(\"Path to dataset files:\", path)\n",
        "files = os.listdir(path)\n",
        "print(\"Files in the dataset:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EzNs7EU3HlX",
        "outputId": "2e69ce14-e8c8-4c2b-a499-eb89c31c8ef9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1\n",
            "Files in the dataset: ['asl_alphabet_train', 'asl_alphabet_test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "_bi8mnfd866Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the paths to the training and testing data directories\n",
        "train_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_test/asl_alphabet_test'"
      ],
      "metadata": {
        "id": "gH-_CqItEriI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for resize, ToTensor, and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize all images to 128x128 pixels\n",
        "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
        "])\n",
        "\n",
        "# Create the dataset using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "# Get a single image and its label (e.g., the first image)\n",
        "image, label = train_dataset[0]  # 0 is for the first image\n",
        "\n",
        "# Print the tensor representation of the image\n",
        "print(\"Tensor shape:\", image.shape)  # e.g., (C, H, W) -> (3, 128, 128)\n",
        "print(\"Tensor values (first 10 pixels):\", image.view(-1)[:10])  # Flatten the tensor and show first 10 pixel values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gATnn1g5BByu",
        "outputId": "8647b9b1-8683-45b3-c796-d68ecb274162"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([3, 128, 128])\n",
            "Tensor values (first 10 pixels): tensor([-0.9922, -0.9294, -0.9529, -0.9765, -0.9686, -0.9608, -0.9686, -0.9765,\n",
            "        -0.9608, -0.9216])\n"
          ]
        }
      ]
    }
  ]
}