{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEirUVncOfq7hKFk3DUfeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendrikyong/CVNL_Assignment_1/blob/main/CVNL_P02_GP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "# List files in the dataset folder\n",
        "print(\"Path to dataset files:\", path)\n",
        "files = os.listdir(path)\n",
        "print(\"Files in the dataset:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EzNs7EU3HlX",
        "outputId": "8d79d2e8-cc1a-462e-ceee-e4e0bd4b0ded"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1\n",
            "Files in the dataset: ['asl_alphabet_train', 'asl_alphabet_test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the paths to the training and testing data directories\n",
        "train_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_test/asl_alphabet_test'\n",
        "\n",
        "# List files in the train and test directories\n",
        "train_files = os.listdir(train_dir)\n",
        "test_files = os.listdir(test_dir)\n",
        "\n",
        "print(\"Files in the training directory:\", train_files)\n",
        "print(\"Files in the testing directory:\", test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bi8mnfd866Z",
        "outputId": "29ecc60e-a5b5-4b9f-b0ef-fb46b08ba96b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the training directory: ['nothing', 'S', 'I', 'H', 'space', 'Q', 'J', 'X', 'G', 'B', 'D', 'R', 'N', 'P', 'A', 'K', 'M', 'E', 'O', 'del', 'W', 'C', 'L', 'F', 'T', 'V', 'Z', 'Y', 'U']\n",
            "Files in the testing directory: ['nothing_test.jpg', 'W_test.jpg', 'I_test.jpg', 'B_test.jpg', 'L_test.jpg', 'space_test.jpg', 'O_test.jpg', 'S_test.jpg', 'V_test.jpg', 'N_test.jpg', 'H_test.jpg', 'R_test.jpg', 'J_test.jpg', 'T_test.jpg', 'Q_test.jpg', 'X_test.jpg', 'D_test.jpg', 'E_test.jpg', 'C_test.jpg', 'M_test.jpg', 'P_test.jpg', 'Z_test.jpg', 'G_test.jpg', 'F_test.jpg', 'Y_test.jpg', 'U_test.jpg', 'A_test.jpg', 'K_test.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define transformations for resize, toTensor, and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),       # Resize all images to 128x128 pixels\n",
        "    transforms.ToTensor(),             # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
        "])"
      ],
      "metadata": {
        "id": "gATnn1g5BByu"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}