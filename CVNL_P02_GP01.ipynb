{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3SZCbJwZYq/ANiVYo1cU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendrikyong/CVNL_Assignment_1/blob/main/CVNL_P02_GP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Download dataset from KaggleHub\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "#define paths to the training and testing data directories\n",
        "data_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train'\n",
        "# no longer using the test_dir because there is only 1 image per class and there is simply not enough for evaluation\n",
        "# test_dir = '/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_test/asl_alphabet_test'\n",
        "\n",
        "# Check dataset files\n",
        "print(\"Path to dataset:\", data_dir)\n",
        "\n",
        "# Normalization values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Define image transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomCrop(128, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Load full dataset (folders act as labels)\n",
        "full_dataset = datasets.ImageFolder(root=data_dir)\n",
        "\n",
        "# Define train-validation split\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms after the split (to avoid validation augmentation)\n",
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Print dataset summary\n",
        "print(f\"Total images: {len(full_dataset)}\")\n",
        "print(f\"Training images: {len(train_dataset)}\")\n",
        "print(f\"Validation images: {len(val_dataset)}\")"
      ],
      "metadata": {
        "id": "mC-GJyNi19k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model cnn model\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "'''\n",
        "typical architecture of a CNN\n",
        "1. input\n",
        "2. conv\n",
        "3. relu\n",
        "4. pooling\n",
        "5. fully connected layers\n",
        "5. output pred\n",
        "\n",
        "considerations:\n",
        "how many conv layers do i need for feature extraction?\n",
        "how many hidden layers?\n",
        "how many channels?\n",
        "'''\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=29):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # conv1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # conv2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # conv3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 16 * 16, 512),  # Correct input size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        #print(x.shape)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4FIPs_cB1-VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Make sure to import tqdm\n",
        "\n",
        "def train(model, train_loader, loss_func, optimizer, device, epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Initialize tqdm progress bar for the current epoch\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update epoch loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Update the progress bar with current metrics\n",
        "            progress_bar.set_postfix({\n",
        "                \"Loss\": f\"{epoch_loss / (batch_idx + 1):.4f}\",  # Average loss so far\n",
        "                \"Acc\": f\"{100. * correct / total:.2f}%\"        # Current accuracy\n",
        "            })\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch+1}: Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100. * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "oAgQODJf2Acv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, loss_func, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Disable gradient computation for testing\n",
        "    with torch.no_grad():\n",
        "        # Initialize tqdm progress bar for the test loop\n",
        "        progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "\n",
        "            # Update test loss and accuracy\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Update the progress bar with current metrics\n",
        "            progress_bar.set_postfix({\n",
        "                \"Loss\": f\"{test_loss / (batch_idx + 1):.4f}\",  # Average loss so far\n",
        "                \"Acc\": f\"{100. * correct / total:.2f}%\"        # Current accuracy\n",
        "            })\n",
        "\n",
        "    # Print final test metrics\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    return avg_test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "9BeR95oZ2CiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, loss function, optimizer, etc.\n",
        "#check if gpu available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(device)\n",
        "\n",
        "model = CNN(num_classes=29).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "epochs = 10\n",
        "lr = 1e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Call the train function\n",
        "train(model, train_loader, loss_func, optimizer, device, epochs=10)\n",
        "test_loss, test_accuracy = test(model, val_loader, loss_func, device)"
      ],
      "metadata": {
        "id": "K_OzhnYB2Frn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}