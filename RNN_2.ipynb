{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendrikyong/CVNL_Assignment_1/blob/main/RNN_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "54QPCHP27lZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21199854-9e7b-4df4-e6d3-00fb7b8430a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths from Hugging Face\n",
        "splits = {\n",
        "    'train': 'hf://datasets/dair-ai/emotion/split/train-00000-of-00001.parquet',\n",
        "    'validation': 'hf://datasets/dair-ai/emotion/split/validation-00000-of-00001.parquet',\n",
        "    'test': 'hf://datasets/dair-ai/emotion/split/test-00000-of-00001.parquet'\n",
        "}\n",
        "\n",
        "# Load datasets using pandas\n",
        "train_df = pd.read_parquet(splits[\"train\"])\n",
        "val_df = pd.read_parquet(splits[\"validation\"])\n",
        "test_df = pd.read_parquet(splits[\"test\"])\n",
        "\n",
        "# Display dataset samples\n",
        "print(\"Train Data Sample:\\n\", train_df.head())\n",
        "print(\"Validation Data Sample:\\n\", val_df.head())\n",
        "print(\"Test Data Sample:\\n\", test_df.head())\n",
        "\n",
        "# Extract text and labels\n",
        "train_texts, train_labels = train_df[\"text\"].tolist(), train_df[\"label\"].tolist()\n",
        "val_texts, val_labels = val_df[\"text\"].tolist(), val_df[\"label\"].tolist()\n",
        "test_texts, test_labels = test_df[\"text\"].tolist(), test_df[\"label\"].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sqnkOFJ889X",
        "outputId": "eeeb89d6-939a-4b77-bf70-546199dd75d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Sample:\n",
            "                                                 text  label\n",
            "0                            i didnt feel humiliated      0\n",
            "1  i can go from feeling so hopeless to so damned...      0\n",
            "2   im grabbing a minute to post i feel greedy wrong      3\n",
            "3  i am ever feeling nostalgic about the fireplac...      2\n",
            "4                               i am feeling grouchy      3\n",
            "Validation Data Sample:\n",
            "                                                 text  label\n",
            "0  im feeling quite sad and sorry for myself but ...      0\n",
            "1  i feel like i am still looking at a blank canv...      0\n",
            "2                     i feel like a faithful servant      2\n",
            "3                  i am just feeling cranky and blue      3\n",
            "4  i can have for a treat or if i am feeling festive      1\n",
            "Test Data Sample:\n",
            "                                                 text  label\n",
            "0  im feeling rather rotten so im not very ambiti...      0\n",
            "1          im updating my blog because i feel shitty      0\n",
            "2  i never make her separate from me because i do...      0\n",
            "3  i left with my bouquet of red and yellow tulip...      1\n",
            "4    i was feeling a little vain when i did this one      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all words from training set\n",
        "all_words = [word for sentence in train_texts for word in word_tokenize(sentence.lower())]\n",
        "\n",
        "# Create vocabulary mapping\n",
        "word_to_idx = {word: idx + 2 for idx, word in enumerate(Counter(all_words))}\n",
        "word_to_idx[\"<PAD>\"] = 0\n",
        "word_to_idx[\"<UNK>\"] = 1  # For unknown words\n",
        "\n",
        "# Define max sequence length\n",
        "MAX_LENGTH = 30\n",
        "\n",
        "# Convert text to sequence of tokens\n",
        "def encode_text(text, word_to_idx, max_len=MAX_LENGTH):\n",
        "    tokens = [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in word_tokenize(text.lower())]\n",
        "    return tokens[:max_len] + [word_to_idx[\"<PAD>\"]] * (max_len - len(tokens))\n",
        "\n",
        "# Encode datasets\n",
        "train_sequences = [encode_text(text, word_to_idx) for text in train_texts]\n",
        "val_sequences = [encode_text(text, word_to_idx) for text in val_texts]\n",
        "test_sequences = [encode_text(text, word_to_idx) for text in test_texts]\n",
        "\n",
        "# Convert labels to tensor\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "print(\"Sample encoded text:\", train_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4VMVit39tkq",
        "outputId": "56d69525-5965-44c9-b5a5-bce632ef455b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample encoded text: [2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, text_sequences, labels):\n",
        "        self.text_sequences = text_sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.text_sequences[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = EmotionDataset(train_sequences, train_labels)\n",
        "val_dataset = EmotionDataset(val_sequences, val_labels)\n",
        "test_dataset = EmotionDataset(test_sequences, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Dataset Sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt0uUp2TCkVe",
        "outputId": "8676a685-9f31-4c7e-cd18-9e052ecf3964"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Sizes - Train: 16000, Val: 2000, Test: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.3):\n",
        "        super(EmotionLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x_embedded)\n",
        "        last_hidden = lstm_out[:, -1, :]\n",
        "        return self.fc(last_hidden)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmotionLSTM(len(word_to_idx), embed_dim=128, hidden_dim=32, num_classes=6).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjWEfv0nCqCA",
        "outputId": "a7e8c6ba-2d76-4918-a9b1-beeec1fd87e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmotionLSTM(\n",
            "  (embedding): Embedding(15212, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer, loss function\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function with validation and test accuracy evaluated only after all epochs\n",
        "def train_model_with_test_eval(model, train_loader, val_loader, test_loader, optimizer, criterion, device, epochs=15):\n",
        "    train_losses = []   # List to track training losses\n",
        "    train_accuracies = []   # List to track training accuracies\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\") as pbar:\n",
        "            for texts, labels in pbar:\n",
        "                texts, labels = texts.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(texts)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Track loss and accuracy\n",
        "                train_loss += loss.item()\n",
        "                train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "                # Update progress bar\n",
        "                pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy = (train_correct / train_total) * 100\n",
        "\n",
        "        # Append training metrics for plotting later\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        print(f\"Epoch {epoch+1}:\\n  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    # Return training metrics for visualization\n",
        "    return train_losses, train_accuracies\n",
        "\n",
        "    # Final Validation Step\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = (val_correct / val_total) * 100\n",
        "    print(\"\\nFinal Validation Results:\")\n",
        "    print(f\"  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Final Test Evaluation\n",
        "    test_loss, test_correct, test_total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in test_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "    # Calculate test metrics\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = (test_correct / test_total) * 100\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Call the updated training function\n",
        "train_losses, train_accuracies = train_model_with_test_eval(model, train_loader, val_loader, test_loader, optimizer, criterion, device, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA6PVqbwCw0Y",
        "outputId": "d8cef682-0093-4c41-c49e-6d88cbfe0441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/15:   0%|          | 0/500 [00:00<?, ?it/s]<ipython-input-4-21e030c06cfa>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self.text_sequences[idx]), torch.tensor(self.labels[idx])\n",
            "Epoch 1/15:  75%|███████▍  | 374/500 [00:27<00:07, 15.81it/s, loss=1.4079]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function to calculate test loss, accuracy, and predictions\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    test_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in test_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predictions.cpu().numpy())\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_test_loss, accuracy, y_true, y_pred"
      ],
      "metadata": {
        "id": "Va9drKO9pVxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Train Loss vs Train Accuracy\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
        "\n",
        "# Plot Train Loss on the first axis\n",
        "ax1.set_xlabel('Training Epochs')\n",
        "ax1.set_ylabel('Train Loss', color='tab:blue')\n",
        "ax1.plot(epochs, train_losses, label='Train Loss', color='tab:blue', marker='o')\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "# Create a second y-axis for accuracy\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('Train Accuracy (%)', color='tab:green')\n",
        "ax2.plot(epochs, train_accuracies, label='Train Accuracy', color='tab:green', marker='o')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
        "\n",
        "# Title and grid\n",
        "plt.title('Train Loss vs Train Accuracy')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Combine legends from both axes\n",
        "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EYkDhL7MpW6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy, y_true, y_pred = evaluate_model(model, test_loader, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[str(i) for i in range(6)]))  # Replace with class names if available\n",
        "\n",
        "# Generate confusion matrix\n",
        "confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[str(i) for i in range(6)], yticklabels=[str(i) for i in range(6)])\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nvMEDNhpY9H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}